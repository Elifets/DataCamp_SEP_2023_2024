---
title: "Pr√©requis des math√©matiques"
editor: visual
---

## Fondements de Probabilit√© ![](images/d%C3%A9.png){width="42"}

### Quelques d√©finitions

-   On appelle √©preuve E toute exp√©rience probabiliste.

-   On appelle univers de E l'ensemble, g√©n√©ralement not√© **Œ©**, de tous les r√©sultats possibles de l'√©preuve E (appel√©s ''√©v√©nements √©l√©mentaires'')

-   Lancer une paire de d√©s √©quilibr√©s et en retenir la somme est une √©preuve.

$$
ùõÄ = \bigl\{ 2,3,4,5,6,7,8,9,10,11,12\bigl\}
$$

### Ev√©nements

Un √©v√©nement est un sous-ensemble de **Œ©**.

-   L'**intersection** de A et B, not√©e $A\ ‚à© B$, est un √©v√©nement. Il est r√©alis√© uniquement si A et B se produisent.

<!-- -->

-   La **r√©union** de A et B, not√©e A *B*, est un √©v√©nement. Il est r√©alis√© si A ou B se produit.

    Deux √©v√©nements remarquables sont √† retenir:

-   L'√©v√©nement certain $ùõÄ_i$.

-   L'√©v√©nement impossible $‚àÖ_i$.

Tous les √©l√©ments qui n'appartiennent pas √† $A$ appartiennent √† un √©v√©nement que l'on appelle le **compl√©mentaire de** $A$**.** On le note $A^c\ ou\ \overline{A}$ .

On dit que deux √©v√©nements **A** et **B** sont **incompatibles** s'ils ne peuvent pas √™tre r√©alis√©s enm√™me temps.

Si A, B et C sont des √©v√©nements de **Œ©**, les propri√©t√©s suivantes sont toujours v√©rifi√©es:

$A\ ‚à™ \ \overline{A}\ = ùõÄ$

$A\ ‚à© \ \overline{A}\ = ‚àÖ$

$\overline{A‚à©B}\ = \bar{A}\ ‚à™\ \bar{B}\ et\ \overline {A‚à™B}\ = \bar{A}\ ‚à©\ \bar{B}\ (lois\ de\ Morgan)$

$A\ ‚à©\ (B\ ‚à™\ C)\ = (A\ ‚à© B)\ ‚à™\ (A\ ‚à©\ C)$

$A\ ‚à™\ (B\ ‚à©\ C)\ = (A\ ‚à™ B)\ ‚à©\ (A\ ‚à™ \ C)$

### Partitions

La famille d'√©v√©nements forme une partition de ùõÄ si :

$$
‚à™_i\ A_i\ =\ \Omega\ et\ A_i\ \cap\ A_j\ = \emptyset;\ \forall i\ \ne\ j;\ i\ \in I
$$

Une partition remarquable est la famille qui contient l'√©v√©nement A et son compl√©mentaire.

### Tribus et bor√©liens

Comment pouvons nous qualifier l'ensemble des √©v√©nements ?

Une tribu est une famille $T$ de parties de l'ensemble $\Omega$ qui v√©rifie les propri√©t√©s suivantes:

-   $\Omega\ \in T$

-   Si $(A_n)_n$ est une suite d√©nombrable d'√©l√©ments de $T_i$ alors $\cup\ A_n\ \in\ T$

Si $A$ est un √©l√©ment de $T_i$ alors son compl√©mentaire l'est aussi

De plus, si $T$ est une tribu, alors:

-   $\emptyset\ \in\ T$

-   Si $(A_n)_n$ est une suite d'√©l√©ments de $T_i$ alors $\cap\ A_n\ \in\ T$.

*Exemple de Tribus:*

Commen√ßons par le cas discret.

On consid√®re l'exp√©rience "Lancer une pi√®ce de monnaie √©quilibr√©e".

On notera: P "Pile apparait" et F "Face apparait".

Dans ce cas, l'univers est l'ensemble {P,F} et $T$ = { $\Omega,\ \emptyset,$ P, F } est une tribu.

En g√©n√©ral, l'ensemble des parties est une tribu (classique).

Pour le cas continu, les intervalles du type $[a, +\infty[\ ;\ ]-\infty,a]$ sont des tribus.

Nous les appelons ***des Bor√©liens***.

Soient A et B deux √©v√©nements. Les propri√©t√©s suivantes sont toujours vraies:

![](images/math.png){fig-align="center"}

1.  $P(\bar{A})\ =\ 1\ -\ P(A)$

2.  $P(B)\ =\ P(A\ \cap\ B)\ +\ P(\bar{A}\ \cap\ B)$

3.  $Si\ A\ \subset\ B\ alors\ P(A)\ \leq\ P(B)$

4.  $0\ \leq\ P(A)\ \leq\ 1$

5.  $P(A\ \cup\ B)\  =\ P(A)\ +\ P(B)\ -\ P(A\ \cap\ B)$

![](images/math3.png){fig-align="center"}

De plus, Consid√©rant une suite $(A_n)_n$ d'√©v√©nements. On a alors :

$$
P(\bigcup\limits_{k=1}^{+\infty} A_{k})\ =  \lim_{x\to+\infty} (P(\bigcup\limits_{k=1}^{n} A_{k})) 
$$

$$
P(\bigcap\limits_{k=1}^{+\infty} A_{k})\ =  \lim_{x\to+\infty} (P(\bigcap\limits_{k=1}^{n} A_{k})) 
$$

$$
P \Bigl( \bigcup\limits_{k=1}^{+\infty} A_{k}
\Bigl)
\ \leq\ \sum_{k=1}^{+\infty}\ P(A_k)
$$

*Et si :*

![](images/math2.png){fig-align="center" width="240"}

$$
\bigcup\limits_{k=1}^{n} A_{k}\ =\ \Omega
$$

*Alors* :

$$
P(B)\ =\ \sum_{k=1}^{n}\ P(B\ \cap\ A_k)
$$

### Mesure

Soit E un ensemble muni d'une tirbu $T$ . On appelle mesure toute application m : $T$ $\rightarrow$ $R^+$ telle que:

-   m($\emptyset$) = 0.

-   Si $(A_n)_n$ est une suite d'√©l√©ments de $T$ deux √† deux disjoints alors:

$$
m(\cup_n\ A_n)\ =\ \Sigma_n\ m(A_n)
$$

### Probabilit√©

Soit E un ensemble muni d'une tribu $T$ On appelle probabilit√© toute m : $T\ \rightarrow\ R^+$ telle que:

-   P($\emptyset$) = 0

-   Si $(A_n)_n$ est une suite d'√©l√©ments de $T$ deux √† deux ***disjoints*** alors:

    $$
    P(\cup_n\ A_n)\ =\ \Sigma_n\ P(A_n)
    $$

### Probabilit√©s conditionnelles

En th√©orie des probabilit√©s, nous nous int√©ressons souvent au comportement d'un al√©a, sachant qu'un autre √©v√©nement est d√©j√† pass√©.

C'est ce que nous appelons **Les Probabilit√©s Conditionnelles.**

Consid√©rant deux √©v√©nements de proba non nulles A et B, la probabilit√© conditionnelle de A sachant que B est r√©alis√© (couramment dit A sachant B) est :

$$
P(A\setminus B)\ =\ 
\frac{P(A\ \cap\ B)}{P(B)}
$$

Par commutativit√© de l'intersection nous avons : $P(A\ \cap\ B)\ =\ P(B\ \cap\ A)$

Et donc en utilisant la formule ci-dessus :

$$
P(B\setminus A)P(A)\ =\ P(A\setminus B)P(B)
$$

D'o√π alors :

$$
P(B\setminus A)\ =\ 
\frac{P(A\setminus B)P(B)}{P(A)}
$$

C'est ce que nous appelons : ***La formule de BAYES***

### Ind√©pendance

Deux √©v√©nements A et B sont dits ind√©pendants si et seulement si :

$$
P(A\ \cap\ B)\ =\ P(A)P(B)
$$

En termes courants, deux √©v√©nements sont ind√©pendants si le r√©sultat de l'un n'influence aucunement l'aboutissement de l'autre.

Sous condition d'ind√©pendance de A et B, la notion de la probabilit√© conditionnelle tombe √† l'eau, car les √©v√©nements √©voluent l'un sans se soucier de l'autre.

Ceci se traduit par :

$$
P(A\setminus B)\ =\ P(A)\\P(B\setminus A)\ =\ P(B)
$$

Notons que si A est ind√©pendant de B, il le sera par rapport √† son copl√©mentaire √©galement et vice versa.

En g√©n√©ral, pour une suite $(A_n)_n$ d'√©v√©nements ind√©pendants, on a :

$$
P(\bigcap_{i=1}^{n}A_i)\ =\ \prod_{i=1}^{n} P(A_i)\ =\ P(A_1)\ ...\ P(A_n)
$$

Cette formule est largement utilis√©e en statistique.

***Remarque importante :***

Il ne faut pas confondre l'ind√©pendance et l'incompatibilit√© des √©v√©nements.

### Variable al√©atoire

Une variable al√©atoire est un nombre qui d√©pend du r√©sultat d'une exp√©rience al√©atoire. Chaque ex√©cution de l'exp√©rience g√©n√®re une r√©alisation de la variable al√©atoire.

Math√©matiquement, on d√©finit une variable al√©atoire X comme une fonction X : $T\ \rightarrow\ R$ qui associe √† chaque √©v√©nement S, un r√©el X(S).

Par exemple, dans une queue pour la caisse d'un magasin, le nombre de clients est une variable al√©atoire. La dur√©e de traitement de chaque requte aussi.

Remarquons que la premi√®re est un nombre entier. On dit qu'elle est √† support discret. Alors que la deuxi√®me est une dur√©e (un nombre r√©el). On dit qu'elle est √† support continu.

### Qu'est ce qui caract√©rise une variable al√©atoire ?

#### Fonction de r√©partition

Une VA traduit le r√©sultat d'une exp√©rience al√©atoire en nombre r√©el. La fontion de r√©partition transporte le calcul des probabilit√©s concernant les r√©alisations de la VA.

C'est la fonction d√©finie par :

$$
F_x(x)\ =\ P(X\ \leq\ x)
$$

Propri√©t√©s :

$$
\forall x;\ 0\leq F_x(x)\leq 1
$$

$F_x$ est une fonction croissante.

$$
\lim_{x\to-\infty} F_x(x)\ =\ 0\\\lim_{x\to\infty} F_x(x)\ =\ 1
$$

![](images/math6.png){fig-align="center" width="347"}

**Cas discret** **Cas continu**

#### Probabilit√© ponctuelle / Densit√©

**Cas discret : Probabilit√© ponctuelle**

La probabilit√© ponctuelle est la fonction qui d√©crit les sauts de la fonction de r√©partition :

$$
P(X=K)\ =\ P(X\leq K)\ -\ P(X\leq K-1)\ =\ P_K
$$

![](images/math5.png){fig-align="center"}

**Cas continu : densit√© de probabilit√©**

La densit√© est la fonction qui d√©crit les variations de la fonction de r√©partition :

$$
f_x(x)\ =\ \frac{\delta F_x}{\delta x}(x)\\\int f_x = 1
$$

### Moments

***Esp√©rance***

L'√©sp√©rance d'une variable al√©atoire est sa valeur attendue. C'est une mesure de localisation de la distribution.

Dans le cas discret :

$$
E(X)= \sum_{k\in X(\Omega)} k.P(X=k)
$$

Alors que dans le cas continu :

$$
E(X) = \int_{x\in X(\Omega)} x.f_x(x).dx
$$

Th√©ror√®me de Transfert :

$$
E(\phi(X)) = \sum_{k\in X(\Omega)} \phi(k).P(X=k)\\ E(\phi(X)) = \int_{x\in X(\Omega)} \phi(x).f_x(x).dx
$$

***Variance***

La variance d'une variable al√©atoire d√©crit la dispersion de la variable al√©atoire autour de sa valeur moyenne (son esp√©rance). Elle est d√©finie par :

$$
V(X)=E(X^2)\ -\ (E(X))^2\ =\  E((x\ -\ E(X)^2)
$$

Sa racine carr√©e est appel√©e √©cart-type et not√©e g√©n√©ralement :

$$
\sigma(X)= \sqrt{V(X)}
$$

***Centrage et r√©duction***

Le centrage consiste √† localiser la distribution autour de l'origine et la r√©duction consiste √† normaliser la dispersion. La technique est simple :

$$
Y= \frac{X\ -\ E(X)}{\sigma (X)}
$$

***Moments d'ordre r :***

Le moment d'ordre r est d√©fini par :

$$
\mu_r = E(X^r)
$$

Le moment centr√© d'ordre r est d√©fini ainsi :

$$
\tilde{\mu_r}= E((X\ -\ E(X))^r)
$$

### Couples al√©atoires

La fonction $F_{x,y}(x,y) = P(X\leq x\ \cap\ Y\leq y)$ est dite distribution conjointe de X et de Y.

Dans le cas continu, la fonction d√©finie par :

$$
f_{x,y}(x,y) = \frac{\delta^2}{\delta_x \delta_y} F_{x,y}(x,y)
$$

Est une densit√© conjointe du couple (X,Y). On a donc :

$$
F_{x,y}(x,y) = \int_{-\infty}^{x} \int_{-\infty}^{y} f_{x,y}(t,u)dtdu
$$

Dans le cas discret, on d√©finit la fonction de fr√©quences conjointes :

$$
P(X=x_i,Y=y_j) = p_{ij}
$$

Et on a donc :

$$
F_{x,y}= \sum_{i:x_i\leq x}\sum_{j:y_j\leq y} p_{ij}
$$

***Loi marjinale***

On d√©finit la loi marginale de X:

$$
f_x(x) = \int_{-\infty}^{+\infty} f_{x,y}(x,y)dy
$$

Dans le cas continu, ou encore :

$$
f_x(x_i) = \sum_j p_{ij}
$$

Dans le cas discret :

(De meme on peut d√©finir la densit√© marginale de Y)

Si X et Y sont ind√©pendants, alors :

$$
f_{x,y}(x,y) = f_x(x)f_y(y)
$$

***Covariance***

La covariance mesure l'intensit√© de la relation lin√©aire entre deux variables al√©atoires X et Y.

$$
Cov(X,Y) = E(XY)\ -\ E(X)E(Y)
$$

Si X et Y sont ind√©pendants, alors :

$$
Cov(X,Y) = 0
$$

*Attention* : La r√©ciproque n'est pas vraie.

### √Ä m√©moriser

Soient U, V, X et Y des variables al√©atoires et a, b, c et d des constantes r√©elles.

***Esp√©rance***

$$
E(aX + bY)\ =\ aE(X) + bE(Y)\\
E(a) = a
$$

***Variance***

$$
V(aX) = a^2 V(X)
$$

$$
V(A)=0
$$

$$
V(X+Y) = V(X)+V(Y)-2Cov(X,Y)
$$

$$
V(X-Y)=V(X)+V(Y)-2Cov(X,Y)
$$

***Covariance***

$$
Cov(X,Y)=Cov(Y,X)
$$

$$
Cov(aX+b,cY+d)= ac.Cov(X,Y)
$$

$$
Cov(aX+bY,U)=aCov(X,U)+bCov(Y,U)
$$

$$
Cov(X,cU+dV)=cCov(X,U)+dCov(X,V)
$$

$$
Cov(aX+bY,cU+dV)=ac.Cov(X,U)+adCov(X,U)+bcCov(Y,U)+bdCov(Y,V)
$$

### Vecteurs al√©atoires

Un vecteur al√©atoire est un n-uplet form√© de variables al√©atoires. On note $(X_1,X_2,‚Ä¶,X_n)^t$

L'esp√©rance est toujours lin√©aire. Pour une suite $(a_i)_{i\in \left\{1,‚Ä¶,n\right\}}$ de r√©els, on a :

$$E(a_1X_1+a_2X_2+...+a_nX_n)= a_1E(X_1)+a_2E(X_2)+...+a_nE(X_n)$$Pour les variables ind√©pendantes, on a :

$$V(X_1 +X_2
+...+ X_n) = V(X_1)+ ...+V(X_n)
$$

### Lois usuelles

***Lois disc√®tes***

![](images/Lois_discr%C3%A8tes-01.png){fig-align="center"}

***Lois absolument continues***

![](images/Lois_continues.png){fig-align="center"}

***Th√©or√®me de Fisher :***

Soient $\sigma > 0,\ m\in \mathbb{R}\ et\ X_1,...,X_n$ des variables al√©atoires ind√©pedantes et de m√™me loi $N(m,\sigma^2)$. Alors, si $X=(X_1, ‚Ä¶, X_n)$ :

-   $\bar{X_n}\ et\ S_n(X)$ sont ind√©pedantes;

-   $(n-1)S_n^2\  /\  \sigma^2 \thicksim \chi^2_{n-1}$;

-   $\sqrt{n}(\bar{X}_n - m)\ /\ S_n(X)\thicksim \tau_{n-1}$;

***Th√©or√®me de Cochran :***

Soient $\sigma > 0, X \thicksim N_n(0,\sigma^2)$ et $V_1 \oplus ‚Ä¶ \oplus V_p$ une d√©composition de $\mathbb{R}^n$ en sous-espaces vectoriels orthogonaux de dimensions $r_1, ‚Ä¶ , r_p$.

Alors les projectons orthogonales $\pi_1, ‚Ä¶ , \pi_p$ de X sur $V_1, ‚Ä¶ , V_p$ sont des vecteurs gaussiens ind√©pendants et pour chaque i = 1, ... , p:

$$
\frac{1}{\sigma^2}\ ||\pi_i||^2 \thicksim \chi^2_{r_i}
$$

## Statistique inf√©rentielle

### L'√©chantillonnage

Soit X une v.a. sur $\Omega$ . Un √©chantillon de X de taille n est un n-uplet $(X_i , ‚Ä¶, X_n)$ de v.a. iid.

Une r√©alisation de cet √©chantillon est un n-uplet de r√©els $(x_1, ‚Ä¶, x_n)$ o√π $X_i(\omega) = x_i$.

### Estimateur

Un estimateur de $\theta$ est une statistique $\widehat{\theta}$ (donc une fonction de $(X_1, ‚Ä¶, X_n)$) qui ne d√©pend pas de $\theta$ et dont la r√©alisation est envisag√©e comme une "bonne valeur" du param√®tre $\theta$.

### Risque quadratique

La qualit√© d'un estimateur est mesur√©e √† travers son risque quadratique d√©finie par :

$$
R_{\widehat{\theta}}(\theta) = V(\widehat{\theta}) + b_{\widehat{\theta}}^2(\theta)
$$

### Biais

On appelle biais d'un estimateur $\widehat{\theta}$ pour $\theta$ la valeur :

$$
b_{\widehat{\theta}}(\theta) = E(\widehat{\theta}) - \theta
$$

Un estimateur T est dit sans biais si :

$$
E(\widehat{\theta}) = \theta
$$

### Statistique

On appelle statistique sur un n-√©chantillon une fonction mesurable de $(X_1, ‚Ä¶, X_n)$ ne d√©pendant pas de $\theta$.

### Consistance

Un estimateur $\widehat{\theta}$ est dit fortement consistant s'il converge en presque-s√ªrement vers $\theta$ lorsque $n\rightarrow +\infty$.

### Moyenne empirique

On appelle moyenne de l'√©chantillon ou moyenne empirique, la statistique not√©e $\bar{X}$ d√©finie par :

$$
\bar{X} = \frac{1}{n} \sum_{i=1}^{n} X_i
$$

### Variance empirique

On appelle variance empirique non biais√©e, la statistique not√©e $S_n^2$ d√©finie par :

$$
S_n^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i\ -\ \bar{X})
$$

### Estimation par la m√©thode du maximum de vraisemblance

On appelle fonction de vraisemblance de $\theta$ d'un n-√©chantillon, la fonction suivante :

$$
V_{x_1, ..., x_n}(\theta) = f_{x_1, ..., x_n}(x_1, ..., x_n) = \prod_{i=1}^nf_{x_1,\theta}(x_i)
$$

avec

$$
f_{x_1,\theta}(x_i) = \left\{
    \begin{array}{ll}
       f_{X,\theta}(x)\ lorsque\ X\ est\ une\ v.a.\ continue\ de \ densit√©\ f_{X,\theta}\\
       P_{X,\theta}(x)\ lorsque\ X\ est\ une\ v.a.\ discr√®te\ de\ probabilit√©\ ponctuelle\ P_{X,\theta}
    \end{array}
\right.
$$

La m√©thode consistant √† estimer $\theta$ par la valeur qui maximise V (vraisemblance) s'appelle m√©thode du maximum de vraisemblance.

Les √©tapes √† suivre sont les suivantes :

-   Calculer la fonction de vraisemblance ci-dessus;

-   Calculer le log de la fonction de vraisemblance not√© L;

-   Calculer la d√©riv√©e de la log-vraisemblance obtenue par rapport √† $\theta$;

-   Trouver la valeur $\widehat{\theta}$ qui annule la d√©riv√©e;

-   V√©rifier que la d√©riv√©e seconde par rapport √† $\theta$ est n√©gative en $\widehat{\theta}$.

En r√©sum√©, si la d√©riv√©e premi√®re s'annulle en $\theta = \widehat{\theta}$ et que la d√©riv√©e seconde est n√©gative en $\theta = \widehat{\theta}$, alors $\widehat{\theta}$ est un maximum local de $V_{x_1, ‚Ä¶, x_n}(\theta$).

### Intervalle de confiance

Un intervalle de confiance permet d'avoir une id√©e de la marge d'erreur de l'√©chantillon repr√©sentatif s√©lectionn√©. En estimant cette marge d'erreur, on est donc en mesure de faire une estimation assez pr√©cise de ce qu'aurait √©t√© le r√©sultat r√©el.

![](images/confiance.png){fig-align="center" width="675" height="394"}

### Test d'hypoth√®ses

Un test d'hypoth√®ses sert √† r√©pondre √† une question donnant 2 r√©sultats alternatives compl√©mentaires. Il faut alors d√©finir :

-   La question (des hypoth√®ses);

-   Une fa√ßon d'y r√©pondre (une r√®gle de d√©cision).

### Hypoth√®se

Une hypoth√®se est un ensemble de valeurs des param√®tres inconnus de la population.

Dans une question, on distingue en g√©n√©ral deux hypoth√®ses √©tant :

-   Une hypoth√®se nulle, not√©e $H_o$ :

    $$
    H_o : \theta\ \in\ \theta_o
    $$

-   Une hypoth√®se alternative, not√©e $H_1$:

    $$
    H_1 : \theta\ \notin\ \theta_0
    $$

Avec $\theta_o$ une valeur sp√©cifi√©e pour un param√®tre $\theta$ de la population.

### Test et test param√©trique

Un test est la donn√©e d'un jeu d'hypoth√®se et d'une r√®gle de d√©cision.

Un test peut √™tre unilat√©ral si l'hypoth√®se $H_1$ s'exprime sous forme d'in√©galit√©s strictes ou bilat√©ral si $H_1$ s'exprime sous forme de diff√©rences ($\neq$).

Un test param√©trique est un test pour lequel des hypoth√®ses sur la distribution des populations sont requises.

### Erreurs et risques

Lorsqu'on prend l'hypoth√®se nulle, la valeur estim√©e $\theta_o$ pour un param√®tre $\theta$ de la population peut conduire √† des erreurs. Ces erreurs sont habituellement class√©s en 2 cat√©gories :

-   L'erreur de premi√®re esp√®ce;

-   L'erreur de seconde esp√®ce

Chaque erreur entraine un risque qui lui correspond :

-   Le risque de premi√®re esp√®ce, not√©e $\alpha$, est le risque de rejeter l'hypoth√®se $H_o$ alors qu'en r√©alit√© cette hypoth√®se est vraie;

-   Le risque de seconde esp√®ce, not√©e $\gamma$, est le risque d'accepter l'hypoth√®se $H_o$ alors qu'en r√©alit√© cette hypoth√®se est fausse

Le tableau suivant r√©sume l'ensemble des couples (d√©cisions/r√©alit√©s) possibles :

![](images/tableau.png){fig-align="center"}

La quantit√© $\beta$ est une probabilit√© de bonne d√©cision appel√©e puissance du test.

Lien utile : [R√©capitulatif des tests statistiques](https://www.imo.universite-paris-saclay.fr/~pierre.pansu/web_ifips/Tests.pdf)

## Econom√©trie

### Mod√®le lin√©aire

On cherche √† expliquer / pr√©dire une variable $Y_i$ √† l'aide de p variables al√©atoires $X_i^{(1)}, ‚Ä¶, X_i^{(p)}$.

On consid√®re le mod√®le :

$$
Y_i = X_i^{(1)}\beta_1\ +\ ...\ +\ X_i^{(p)}\beta_p\ +\ \epsilon_i,\ \forall i\ \in\ [1;n].
$$

Pour d√©terminer les param√®tres √† estimer du mod√®le, il est plus simple d'√©crire le mod√®le sous forme matricielle :

$$
Y = X\beta\ +\ \epsilon
$$

$Y \in R^n$ est appel√©e variable endog√®ne, c'est √† dire la variable √† expliquer ou pr√©dire.

$X \in M_{n,p}(R)$ et contient les $X_i^{(1)}, ‚Ä¶, X_i^{(p)}$ qui sont appel√©es variables exog√®nes, c'est √† dire les variables explicatives.

$\beta \in R^p$ contient les param√®tres √† estimer du mod√®le.

$\epsilon \in R^p$ contient le terme d'erreur du mod√®le non observable.

### Hypoth√®ses sur les erreurs

4 **hypoth√®ses sur les erreurs** sont √† v√©rifier dans le cadre d'un mod√®le lin√©aire OLS :

-   $\forall i \in [1;n];\ E(\epsilon_i) = 0$ : les erreurs sont centr√©es;

-   $\forall i \in [1;n];\ V(\epsilon_i) = \sigma^2$ : les erreurs sont homosc√©dastiques;

-   $\forall i\neq j \in [1; n]; E(\epsilon_i,\epsilon_j) = 0$ : les erreurs ne sont pas auto-corr√©l√©es;

-   $\forall i \in [1;n]; \epsilon_i\ ‚àº N(0,\sigma^2)$ : les erreurs sont normalement distribu√©es.

### Hypoth√®ses structurelle

Dans le cadre d'un mod√®le lin√©aire OLS, on doit retrouver 3 hypoth√®ses structurelles :

-   Les variables $X_1, ‚Ä¶, X_p$ sont orthogonales √† $\epsilon$;
-   Les variables $X_1, ‚Ä¶, X_p$ forment une base de $R^{p+1}$;
-   n \> p+1.

### D√©composition de la variance

![](images/Capture%20d%E2%80%99%C3%A9cran%202023-01-21%20124938.png){fig-align="center" width="439"}

L'√©quation d'analyse de la variance est : SCT = SCE + SCR, cela veut dire que la somme des carr√©es totale = somme des carr√©es expliqu√©e + la somme des carr√©es r√©siduelle.

### Coefficient de d√©t√©rmination

Le coefficient de d√©t√©rmination not√© $R^2$ est d√©fini par :

$$
R^2 = \frac{SCE}{SCR}.
$$
